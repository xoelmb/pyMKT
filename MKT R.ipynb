{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Attaching package: ‘dplyr’\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:stats’:\n",
      "\n",
      "    filter, lag\n",
      "\n",
      "\n",
      "The following objects are masked from ‘package:base’:\n",
      "\n",
      "    intersect, setdiff, setequal, union\n",
      "\n",
      "\n",
      "\n",
      "Attaching package: ‘MASS’\n",
      "\n",
      "\n",
      "The following object is masked from ‘package:dplyr’:\n",
      "\n",
      "    select\n",
      "\n",
      "\n",
      "Loading required package: ggplot2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "library(dplyr)\n",
    "library(MASS)\n",
    "library(iMKT)\n",
    "root_dir <- '~/Escritorio/mastersthesis/'\n",
    "data_dir <- paste(root_dir,'data/', sep='')\n",
    "scripts_dir <- paste(root_dir, 'scripts/', sep='')\n",
    "results_dir <- paste(root_dir, 'results/', sep='')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' @title iMKT using PopHuman data\n",
    "#'\n",
    "#' @description Perform any MKT method using a subset of PopHuman data defined by custom genes and populations lists\n",
    "#'\n",
    "#' @details Execute any MKT method (standardMKT, FWW, eMKT, aMKT) using a subset of PopHuman data defined by custom genes and populations lists. It uses the dataframe PopHumanData, which can be already loaded in the workspace (using loadPopHuman()) or is directly loaded when executing this function. It also allows deciding whether to analyze genes groupped by recombination bins or not, using recombination rate values corresponding to the sex average estimates from Bhérer et al. 2017 Nature Commun. \n",
    "#'\n",
    "#' @param genes list of genes to analyze\n",
    "#' @param pops list of populations to analyze\n",
    "#' @param cutoffs list of cutofs to perform FWW and/or eMKT\n",
    "#' @param test which test to perform. Options include: standardMKT (default), eMKT, FWW, aMKT\n",
    "#' @param xlow lower limit for asymptotic alpha fit (default=0)\n",
    "#' @param xhigh higher limit for asymptotic alpha fit (default=1)\n",
    "#' @param plot report plot (optional). Default is FALSE\n",
    "#' \n",
    "#' @return List of lists with the default test output for each selected population (and recombination bin when defined)\n",
    "#'\n",
    "#' @examples\n",
    "#' ## List of genes\n",
    "#' mygenes <- c(\"ENSG00000011021.21_3\",\"ENSG00000091483.6_3\",\"ENSG00000116191.17_3\",\n",
    "#'\t\t\t\t\t\t\t\"ENSG00000116337.15_4\",\"ENSG00000116584.17_3\",\"ENSG00000116745.6_3\",\n",
    "#'\t\t\t\t\t\t\t\"ENSG00000116852.14_3\",\"ENSG00000116898.11_3\",\"ENSG00000117010.15_3\",\n",
    "#'\t\t\t\t\t\t\t\"ENSG00000117090.14_3\",\"ENSG00000117222.13_3\",\"ENSG00000117394.20_3\")\n",
    "#' ## Perform analyses\n",
    "#' PopHumanAnalysis(genes=mygenes , pops=c(\"CEU\",\"YRI\"), test=\"standardMKT\")\n",
    "#' PopHumanAnalysis(genes=mygenes , pops=c(\"CEU\"), test=\"eMKT\")\n",
    "#' \n",
    "#' @import utils\n",
    "#' @import stats\n",
    "#'\n",
    "#' @keywords PopData\n",
    "#' @export\n",
    "\t\t\t\n",
    "PopHumanAnalysisMod <- function(genes=c(\"gene1\",\"gene2\",\"...\"), pops=c(\"pop1\",\"pop2\",\"...\"), cutoff=0.05, test=c(\"standardMKT\",\"eMKT\",\"FWW\",\"aMKT\"), xlow=0, xhigh=1, plot=FALSE, cum=FALSE, daf10=FALSE) { \n",
    "\t\n",
    "\t## Get PopHuman data\n",
    "\tif (exists(\"PopHumanData\") == TRUE) {\n",
    "\tdata <- get(\"PopHumanData\")\n",
    "\t} else {\n",
    "\tloadPopHuman()\n",
    "\tdata <- get(\"PopHumanData\") }\n",
    "\t\n",
    "\t## Check input variables\n",
    "\t## Numer of arguments\n",
    "\tif (nargs() < 2 && nargs()) {\n",
    "\tstop(\"You must specify 2 arguments at least: genes, pops.\\nIf test = asymptoticMKT or test = aMKT, you must specify xlow and xhigh values.\") }\n",
    "\t\n",
    "\t## Argument genes\n",
    "\tif (length(genes) == 0 || genes == \"\" || !is.character(genes)) {\n",
    "\tstop(\"You must specify at least one gene.\") }\n",
    "\tif (!all(genes %in% data$ID) == TRUE) {\n",
    "\tdifGenes <- setdiff(genes, data$ID)\n",
    "\tdifGenes <- paste(difGenes, collapse=\", \")\n",
    "\tstopMssg <- paste0(\"MKT data is not available for the requested gene(s).\\nRemember to use gene IDs from Ensembl (ENSG...).\\nThe genes that caused the error are: \", difGenes, \".\")\n",
    "\tstop(stopMssg) }\n",
    "\t\n",
    "\t## Argument pops\n",
    "\tif (length(pops) == 0 || pops == \"\" || !is.character(pops)) {\n",
    "\tstop(\"You must specify at least one population.\") }\n",
    "\tif (!all(pops %in% data$Population) == TRUE) {\n",
    "\tcorrectPops <- unique(data$Population)\n",
    "\tdifPops <- setdiff(pops, correctPops)\n",
    "\tdifPops <- paste(difPops, collapse=\", \")\n",
    "\tstopMssg <- paste0(\"MKT data is not available for the sequested populations(s).\\nSelect among the following populations:\\n\",correctPops,\"\\nThe populations that caused the error are: \", difPops, \".\")\n",
    "\tstop(stopMssg) }\n",
    "\t\n",
    "\t## Argument test and xlow + xhigh (when necessary)\n",
    "\tif(missing(test)) {\n",
    "\ttest <- \"standardMKT\"\n",
    "\t}\n",
    "\telse if (test != \"standardMKT\" && test != \"eMKT\" && test != \"FWW\" && test != \"aMKT\") {\n",
    "\tstop(\"Parameter test must be one of the following: standardMKT, eMKT, FWW, aMKT, iMKT\")\n",
    "\t}\n",
    "\tif (length(test) > 1) {\n",
    "\tstop(\"Select only one of the following tests to perform: standardMKT, eMKT, FWW, aMKT\") }\n",
    "\tif ((test == \"standardMKT\" || test == \"eMKT\" || test == \"FWW\") && (xlow != 0 || xhigh != 1)) {\n",
    "\twarningMssgTest <- paste0(\"Parameters xlow and xhigh not used! (test = \",test,\" selected)\")\n",
    "\twarning(warningMssgTest) }\n",
    "\t\n",
    "\t## Arguments xlow, xhigh features (numeric, bounds...) checked in checkInput()\n",
    "\t\n",
    "\t## Perform subset\n",
    "\tsubsetGenes <- data[(data$ID %in% genes & data$Population %in% pops), ]\n",
    "\tsubsetGenes$ID <- as.factor(subsetGenes$ID)\n",
    "\tsubsetGenes <- droplevels(subsetGenes)\n",
    "\t\n",
    "\t## Declare output list (each element 1 pop)\n",
    "\toutputList <- list()\n",
    "\t\n",
    "\tfor (i in levels(subsetGenes$Population)) {\n",
    "\t\t# print(paste0(\"Population = \", i))\n",
    "\t\tx <- subsetGenes[subsetGenes$Population == i, ]\n",
    "\t\t\n",
    "\t\t## Set counters to 0\n",
    "\t\tPi <- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)\n",
    "\t\tP0 <- c(0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0)\n",
    "\t\tf <- seq(0.025,0.975,0.05)\n",
    "\t\tmi <- 0; m0 <- 0\n",
    "\t\tDi <- 0; D0 <- 0\n",
    "\t\t\n",
    "\t\t## Group genes\n",
    "\t\tfor (j in levels(x$ID)) {\n",
    "\t\tx1 <- x[x$ID == j, ]\n",
    "\t\t\n",
    "\t\t## DAF\n",
    "\t\tx1$DAF0f <- as.character(x1$DAF0f); x1$DAF4f <- as.character(x1$DAF4f)\n",
    "\t\tdaf0f <- unlist(strsplit(x1$DAF0f, split=\";\"))\n",
    "\t\tdaf4f <- unlist(strsplit(x1$DAF4f, split=\";\"))\n",
    "\t\tdaf0f <- as.numeric(daf0f); daf4f <- as.numeric(daf4f)\n",
    "\t\tPi <- Pi + daf0f; P0 <- P0 + daf4f\n",
    "\t\t\n",
    "\t\t## Divergence\n",
    "\t\tmi <- mi + x1$mi; m0 <- m0 + x1$m0\n",
    "\t\tDi <- Di + x1$di; D0 <- D0 + x1$d0\n",
    "\t\t}\n",
    "\n",
    "\t\t## Proper formats\n",
    "\t\tdaf <- cbind(f, Pi, P0); daf <- as.data.frame(daf)\n",
    "\t\tnames(daf) <- c(\"daf\",\"Pi\",\"P0\")\n",
    "\t\tdiv <- cbind(mi, Di, m0, D0); div <- as.data.frame(div)\n",
    "\t\tnames(div) <- c(\"mi\",\"Di\",\"m0\",\"D0\")\n",
    "\t\t\n",
    "\n",
    "\t\tif (isTRUE(cum)){\n",
    "      daf <- cumulative(daf)\n",
    "\t\t}\n",
    "\t\t\n",
    "\n",
    "\t\t## Check data inside each test!\n",
    "\t\t## Queremos que vaya de 0.05 en 0.05 si los genes son suficientes.\n",
    "\t\t# Transform daf20 to daf10 (faster fitting) for asymptoticMKT and aMKT\n",
    "  \tif (isTRUE(daf10)){\n",
    "\t\t\tif (nrow(daf) == 20) {\n",
    "  \t\tdaf1 <- daf\n",
    "  \t\tdaf1$daf10 <- sort(rep(seq(0.05,0.95,0.1),2)) ## Add column with the daf10 frequencies\n",
    "        print(daf1$daf10)\n",
    "  \t\tdaf1 <- daf1[c(\"daf10\",\"Pi\",\"P0\")] ## Keep new frequencies, Pi and P0\n",
    "  \t\tdaf1 <- aggregate(. ~ daf10, data=daf1, FUN=sum)\t## Sum Pi and P0 two by two based on daf\n",
    "  \t\tcolnames(daf1)<-c(\"daf\",\"Pi\",\"P0\") ## Final daf columns name\n",
    "  \t\t\n",
    "  \t\tdaf <- daf1\n",
    "  \t\t}\n",
    "  \t}\n",
    "\n",
    "\t\t## Perform test\n",
    "\t\tif(test == \"standardMKT\") {\n",
    "\t\toutput <- standardMKT(daf, div) }\n",
    "\t\telse if(test == \"eMKT\" && plot == FALSE) {\n",
    "\t\toutput <- eMKT(daf, div,listCutoffs=cutoff) }\n",
    "\t\telse if(test == \"eMKT\" && plot == TRUE) {\n",
    "\t\toutput <- eMKT(daf, div,listCutoffs=cutoff, plot=TRUE) }\n",
    "\t\telse if(test == \"FWW\" && plot == FALSE) {\n",
    "\t\toutput <- FWW(daf, div, listCutoffs=cutoff) }\n",
    "\t\telse if(test == \"FWW\" && plot == TRUE) {\n",
    "\t\toutput <- FWW(daf, div, listCutoffs=cutoff, plot=TRUE) }\n",
    "\t\telse if(test == \"aMKT\" && plot == FALSE) {\n",
    "\t\toutput <- aMKT(daf, div, xlow, xhigh) }\n",
    "\t\telse if(test == \"aMKT\" && plot == TRUE) {\n",
    "\t\toutput <- aMKT(daf, div, xlow, xhigh, plot=TRUE) }\n",
    "\t\t\n",
    "\t\t## Fill list with each pop\n",
    "\t\toutputList[[paste(\"Population = \",i)]] <- output\n",
    "\t}\n",
    "\t\n",
    "\t## Return output\n",
    "\tcat(\"\\n\")\n",
    "\treturn(outputList)\n",
    "\t\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative <- function(x){\n",
    "\n",
    "\tpsyn  = rep(0,length(x$daf))\n",
    "\tpnsyn = rep(0,length(x$daf))\n",
    "\tpsyn[1]  = sum(x$P0)\n",
    "\tpnsyn[1] = sum(x$Pi)\n",
    "\n",
    "\tfor(i in 2:length(x$daf)){\n",
    "\t\tappS    = psyn[i-1] - x$P0[i-1]\n",
    "\t\tappNsyn = pnsyn[i-1] - x$Pi[i-1]\n",
    "\n",
    "\t\tif( appS > 0.0 & appNsyn > 0.0){\n",
    "\t\t\tpsyn[i]  = appS\n",
    "\t\t\tpnsyn[i] = appNsyn\n",
    "\t\t}\n",
    "\t\telse{\n",
    "\t\t\tpsyn[i]  = 0\n",
    "\t\t\tpnsyn[i] = 0\t\t\n",
    "\t\t}\n",
    "\n",
    "\t}\n",
    "\n",
    "\tx$Pi = pnsyn \n",
    "\tx$P0 = psyn\n",
    "\n",
    "\treturn(x)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeSfs <- function(x,cumu=FALSE){\n",
    "\n",
    "\tf <- seq(0.025,0.975,0.05)\n",
    "\tpi <- do.call(rbind,lapply(as.character(x[['DAF0f']]), function(z) unlist(strsplit(z, split = ';')) %>% as.numeric())) %>% colSums()\n",
    "\tp0 <- do.call(rbind,lapply(as.character(x[['DAF4f']]), function(z) unlist(strsplit(z, split = ';')) %>% as.numeric())) %>% colSums()\n",
    "\tmi <- x[['mi']]\n",
    "\tm0 <- x[['m0']]\n",
    "\tdi <- x[['di']]\n",
    "\td0 <- x[['d0']]\n",
    "    \n",
    "\t## Proper formats\n",
    "\tdaf <- cbind(f, pi, p0) %>% as.data.frame()\n",
    "\tnames(daf) <- c('daf','Pi','P0')\n",
    "\tdiv <- cbind(mi, di, m0, d0) %>% colSums %>% t %>%as.data.frame() \n",
    "\tnames(div) <- c('mi','Di','m0','D0')\n",
    "\n",
    "\tif(cumu == TRUE){\n",
    "\n",
    "\t\tout<-list()\n",
    "\t\tout[['daf']] <- cumulative(daf)\n",
    "\t\tout[['div']] <- div\n",
    "\t\treturn(out)\n",
    "\n",
    "\t}else{\n",
    "\n",
    "\t\tout<-list()\n",
    "\t\tout[['daf']] <- daf\n",
    "\t\tout[['div']] <- div\n",
    "\t\treturn(out)\n",
    "\n",
    "\t}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#' @title eMKT correction method\n",
    "#'\n",
    "#' @description MKT calculation corrected using eMKT method (Mackay et al. 2012 Nature).\n",
    "#'\n",
    "#' @details In the standard McDonald and Kreitman test, the estimate of adaptive evolution (alpha) can be easily biased by the segregation of slightly deleterious non-synonymous substitutions. Specifically, slightly deleterious mutations contribute more to polymorphism than they do to Divergence, and thus, lead to an underestimation of alpha. Because adaptive mutations and weakly deleterious selection act in opposite Directions on the MKT, alpha and the fraction of substitutions that are slighlty deleterious, b, will be both underestimated when both selection regimes occur. To take adaptive and slighlty deleterious mutations mutually into account, Pi, the count off segregatning sites in class i, should be separated into the number of neutral variants and the number of weakly deleterious variants, Pi = Pineutral + Pi weak del. Alpha is then estimated as 1-(Pineutral/P0)(D0/Di). As weakly deleterious mutations tend to segregate at low frequencies, neutral and weakly deleterious fractions from Pi can be estimated based on any frequency cutoff established.\n",
    "#'\n",
    "#' @param daf data frame containing DAF, Pi and P0 values\n",
    "#' @param Divergence data frame containing Divergent and analyzed sites for selected (i) and neutral (0) classes\n",
    "#' @param listCutoffs list of cutoffs to use (optional). Default cutoffs are: 0, 0.05, 0.1\n",
    "#' @param plot report plot (optional). Default is FALSE\n",
    "#' \n",
    "#' @return MKT corrected by the eMKT method. List with alpha results, graph (optional), Divergence metrics, MKT tables and negative selection fractions\n",
    "#'\n",
    "#' @examples\n",
    "#' ## Using default cutoffs\n",
    "#' eMKT(myDafData, myDivergenceData)\n",
    "#' ## Using custom cutoffs and rendering plot\n",
    "#' eMKT(myDafData, myDivergenceData, c(0.05, 0.1, 0.15), plot=TRUE)\n",
    "#'\n",
    "#' @import utils\n",
    "#' @import stats\n",
    "#' @import ggplot2\n",
    "#' @importFrom ggthemes theme_foundation\n",
    "#' @importFrom cowplot plot_grid\n",
    "#' @importFrom reshape2 melt \n",
    "#'\n",
    "#' @keywords MKT\n",
    "#' @export\n",
    "\n",
    "\n",
    "####################################################\n",
    "################# MKT-FWW function #################\n",
    "####################################################\n",
    "\n",
    "eMKT = function(daf, divergence, listCutoffs=0.15, plot=FALSE) {\n",
    "\t\n",
    "\t## Check data\n",
    "# \tcheck = checkInput(daf, divergence, 0, 1)\n",
    "# \tif(check$data == FALSE)\n",
    "# \t{\n",
    "# \t\t stop(check$print_errors) \n",
    "# \t}\n",
    "\t\n",
    "\t## Declare output lists and data frames\n",
    "\toutput     = list()\n",
    "\tmktTables  = list()\n",
    "\tdivMetrics = list()\n",
    "\tdivCutoff  = list()\n",
    "\t\n",
    "\t##Polymorphism and Divergence variables\n",
    "\tP0 = sum(daf[['P0']])\n",
    "\tPi = sum(daf[['Pi']])\n",
    "\tD0 = divergence[['D0']]\n",
    "\tDi = divergence[['Di']]\n",
    "\tm0 = divergence[['m0']]\n",
    "\tmi = divergence[['mi']]\n",
    "\t\n",
    "\t## MKT tables\n",
    "\tmktTableStandard = data.frame(Polymorphism = c(sum(daf[['P0']]), sum(daf[['Pi']])), Divergence = c(D0,Di),row.names = c(\"Neutral class\",\"Selected class\"))\n",
    "\n",
    "    ## Divergence metrics\n",
    "\tKa              = Di/mi\n",
    "\tKs              = D0/m0\n",
    "\tomega           = Ka/Ks\n",
    "\n",
    "\t## Estimation of alpha\n",
    "\t# alpha = 1 - ((Pi/P0)*(D0/Di))\n",
    "\t# alphaC = 1 - ((PiNeutral/P0)*(mktTableStandard[1,2]/mktTableStandard[2,2]))\n",
    "\talphaCorrected <- list()\n",
    "\tfractions <- list()\n",
    "\tfor (c in listCutoffs) {\n",
    "\t\t\n",
    "\t\t## Estimating alpha with Pi/P0 ratio \n",
    "\t\tPiMinus     = sum(daf[daf[['daf']] <= c,'Pi'])\n",
    "\t\tPiGreater   = sum(daf[daf[['daf']] > c,'Pi'])\n",
    "\t\tP0Minus     = sum(daf[daf[['daf']] <= c,'P0'])\n",
    "\t\tP0Greater   = sum(daf[daf[['daf']] > c,'P0'])\n",
    "\t\tratioP0     = P0Minus/P0Greater\n",
    "\t\tdeleterious = PiMinus - (PiGreater * ratioP0)\n",
    "\t\tPiNeutral = Pi - deleterious\n",
    "\n",
    "\t\talphaC = 1 - (((Pi - deleterious)/P0)*(D0/Di))\n",
    "\n",
    "\n",
    "\t\t## Estimation of b: weakly deleterious\n",
    "\t\tb    = (deleterious/P0)*(m0/mi)\n",
    "\t\t\n",
    "\t\t## Estimation of f: neutral sites\n",
    "\t\tf = (m0*PiNeutral)/(as.numeric(mi)*as.numeric(P0))\n",
    "\t\t\n",
    "\t\t## Estimation of d, strongly deleterious sites\n",
    "\t\td = 1 - (f+b)\n",
    "\t\t\n",
    "\t\t## Fisher exact test p-value from the MKT\n",
    "\t\tm      = matrix(c(P0,(Pi - deleterious),D0,Di), ncol=2)\n",
    "\t\tpvalue = fisher.test(round(m))$p.value\n",
    "\t\t\n",
    "\t\t## Omega A and Omega D\n",
    "\t\tomegaA = omega * alphaC\n",
    "\t\tomegaD = omega - omegaA\n",
    "\t\t\n",
    "\t\t## Store output  \n",
    "\t\talphaCorrected[[paste0('cutoff=',c)]] = c(c, alphaC, pvalue)\n",
    "\t\tfractions[[paste0('cutoff=',c)]] = c(c, d, f, b)\n",
    "\t\tdivCutoff[[paste0('cutoff=',c)]] = c(c, Ka,Ks,omegaA, omegaD)\n",
    "\t\t# mktTables[[paste0('cutoff=',c)]]  = mktTableCleaned\n",
    "\t}\n",
    "\n",
    "\t## Fractions\n",
    "\t# names(fraction) = 'Correction'\n",
    "\t\n",
    "\t## Store output \n",
    "\t## Output format\n",
    "\toutput[['mktTable']]                 = mktTableStandard \n",
    "\toutput[['alphaCorrected']]           = as.data.frame(do.call('rbind',alphaCorrected))\n",
    "\tcolnames(output[['alphaCorrected']]) = c('cutoff', 'alphaCorrected', 'pvalue')\n",
    "\t## Divergence metricss\n",
    "\tdivCutoff                            = as.data.frame(do.call('rbind',divCutoff))\n",
    "\tnames(divCutoff)                     = c('cutoff', 'Ka','Ks','omegaA', 'omegaD')\n",
    "\toutput[['divMetrics']]               = list('metricsByCutoff'=divCutoff)\n",
    "\toutput[['fractions']]                = as.data.frame(do.call('rbind',fractions))\n",
    "\tnames(output[['fractions']])                     = c('cutoff', 'd','f','b')\n",
    "\t\n",
    "\t# DivCutoff                     = data.frame('omegaA' = omegaA, 'omegaD' = omegaD)\n",
    "\t# output[['divMetrics']]        = list(DivTable, DivCutoff)\n",
    "\t# names(output[['divMetrics']]) = c(\"Global metrics\", \"Estimates by cutoff\")\n",
    "\t# Results table\n",
    "\t# output = as.data.frame(do.call(\"rbind\",output))\n",
    "\t# colnames(output) = c(\"cutoff\", \"alpha\", \"pvalue\")\n",
    "\t\n",
    "\t# Divergence metrics\n",
    "\t# DivCutoff = as.data.frame(do.call(\"rbind\",DivCutoff))\n",
    "\t# names(DivCutoff) = c(\"omegaA\", \"omegaD\")\n",
    "\n",
    "\t## Render plot\n",
    "\tif (plot == TRUE) {\n",
    "\n",
    "\t\t## Cut-offs graph\n",
    "\t\t# plot = ggplot(output, aes(x=as.factor(cutoff), y=alpha, group=1)) +\n",
    "\t\t# \tgeom_line(color=\"#386cb0\") + \n",
    "\t\t# \tgeom_point(size=2.5, color=\"#386cb0\")+\n",
    "\t\t# \tthemePublication() +\n",
    "\t\t# \txlab(\"Cut-off\") + ylab(expression(bold(paste(\"Adaptation (\",alpha,\")\")))) \n",
    "\t\n",
    "\t\t## Re-format outputs\n",
    "\t\t# output = output[,c(2,3)]\n",
    "\t\t# names(output) = c(\"alpha.symbol\",\"Fishers exact test P-value\")\n",
    "\t\t# DivCutoff = DivCutoff[,c(2,3)]\n",
    "\t\t# colnames(DivCutoff) = c(\"omegaA.symbol\", \"omegaD.symbol\")\n",
    "\t\t# DivMetrics = list(DivTable, DivCutoff)\n",
    "\t\t# names(DivMetrics) = c(\"Global metrics\", \"Estimates by cutoff\")\n",
    "\t\n",
    "\t\t## Melt fractions data\n",
    "\t\tplotAlpha = ggplot(output[['alphaCorrected']], aes(x=as.factor(cutoff), y=alphaCorrected, group=1)) +\n",
    "\t\t\tgeom_line(color=\"#386cb0\") + \n",
    "\t\t\tgeom_point(size=2.5, color=\"#386cb0\")+\n",
    "\t\t\tthemePublication() +\n",
    "\t\t\txlab(\"Cut-off\") + ylab(expression(bold(paste(\"Adaptation (\",alpha,\")\"))))\n",
    "\t\n",
    "\t\t## Fractions graph\n",
    "\t\ti = which.max(output$alphaCorrected$alphaCorrected)\n",
    "\t\tfractionsMelt = output[['fractions']][i,2:4]\n",
    "\t\tfractionsMelt = reshape2::melt(fractionsMelt, id.vars=NULL) \n",
    "\t\tfractionsMelt[['test']] = rep(c('eMKT'),3)\n",
    "\n",
    "\t\tplotFraction = ggplot(fractionsMelt) + geom_bar(stat=\"identity\", aes_string(x=\"test\", y=\"value\", fill=\"variable\"), color=\"black\") +\n",
    "\t\t\tcoord_flip() + themePublication() + ylab(label=\"Fraction\") + xlab(label=\"Cut-off\") +\n",
    "\t\t\tscale_fill_manual(values=c(\"#386cb0\",\"#fdb462\",\"#7fc97f\",\"#ef3b2c\",\"#662506\",\"#a6cee3\",\"#fb9a99\",\"#984ea3\",\"#ffff33\"), breaks=c(\"f\",\"d\",\"b\"), labels=c(expression(italic(\"f\")),expression(italic(\"d\")),expression(italic(\"b\")))) +\n",
    "\t\t\ttheme(axis.line=element_blank()) + scale_y_discrete(limit=seq(0,1,0.25), expand=c(0,0))\n",
    "\t\n",
    "\t\tplotEmkt = plot_grid(plotAlpha, plotFraction, nrow=2,  labels=c('A','B'), rel_heights=c(2,1))\n",
    "\n",
    "\t\toutput[['graph']] = plotEmkt\n",
    "\n",
    "\t\t# plot = plot_grid(plot, plotfraction, nrow=2, labels=c(\"A\",\"B\"), rel_heights=c(2,1))\n",
    "\t\n",
    "\t\t## Return list output  \n",
    "\t\t# output[['Graph']] = plot\n",
    "\t\t# names(listOutput) = c(\"Results\",\"Graph\", \"Divergence metrics\", \"MKT tables\",\"Fractions\")\n",
    "\n",
    "\t\treturn(output)\n",
    "\n",
    "\t## If no plot to render\n",
    "\t} else if (plot==FALSE) {\n",
    "\t\t\t## Re-format outputs\n",
    "\t\t\t# output = output[,c(2,3)]\n",
    "\t\t\t# names(output) = c(\"alpha.symbol\",\"Fishers exact test P-value\")\n",
    "\t\t\t# DivCutoff = DivCutoff[,c(2,3)]\n",
    "\t\t\t# colnames(DivCutoff) = c(\"omegaA.symbol\", \"omegaD.symbol\")\n",
    "\t\t\t# DivMetrics = list(DivTable, DivCutoff)\n",
    "\t\t\t# names(DivMetrics) = c(\"Global metrics\", \"Estimates by cutoff\")\n",
    "\t\t\n",
    "\t\t\t# ## Melt fractions data\n",
    "\t\t\t# fractionsMelt = melt(fractions, id.vars=NULL) \n",
    "\t\t\t# fractionsMelt$Fraction =  rep(c(\"d\", \"f\", \"b\"),length(fractionsMelt$variable)/3)\n",
    "\t\t\t\n",
    "\t\t\t# ## Return list output  \n",
    "\t\t\t# listOutput = list(output, DivMetrics, mktTables, fractions)\n",
    "\t\t\t# names(listOutput) = c(\"Results\", \"Divergence metrics\", \"MKT tables\",\"Fractions\")\n",
    "\n",
    "\t\t\treturn(output)\n",
    "\t}\n",
    "\t\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# for (f in 2:nrow(daf)-1) {\n",
    "# \tcleanedDafBellow = cleanedDaf[1, ]\n",
    "# \tcleanedDafAbove  = cleanedDaf[2:nrow(cleanedDaf), ] ## over cleanedDaf \n",
    "\t\n",
    "# \t## Create MKT table \n",
    "# \tmktTable  = data.frame(`cleanedDaf below cutoff` = c(sum(cleanedDafBellow$P0), sum(cleanedDafBellow$Pi)), `cleanedDaf above cutoff`=c(sum(cleanedDafAbove$P0), sum(cleanedDafAbove$Pi)),row.names = c(\"Neutral class\",\"Selected class\"))\n",
    "\t\n",
    "# \tcleanedPi = sum(cleanedDaf$Pi)\n",
    "\t\n",
    "# \t## Estimate fractions\n",
    "# \tfNeutral  = mktTable[1,1]/sum(cleanedDaf$P0)\n",
    "# \tPiNeutralBelowCutoff = cleanedPi * fNeutral\n",
    "\n",
    "# \t# If we haven't deleterious in Pi then PiNeutral = Pi_in_current_cutoff\n",
    "# \tif(PiNeutralBelowCutoff > cleanedDafBellow[['Pi']]){\n",
    "# \t\tPiNeutral = PiNeutral + cleanedDafBellow[['Pi']]\n",
    "# \t}\n",
    "# \telse{\n",
    "# \t\tPiNeutral = PiNeutral + PiNeutralBelowCutoff\n",
    "# \t}\n",
    "\t\n",
    "# \t## Deleting current frequency \n",
    "# \tcleanedDaf = cleanedDaf[2:nrow(cleanedDaf),]\n",
    "\n",
    "# } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "aMKT = function(daf, divergence, xlow=0, xhigh=1) {\n",
    "\n",
    "\t## Create MKT table standard\n",
    "\tmktTableStandard = data.frame(\n",
    "\t\tPolymorphism = c(sum(daf[['P0']]), sum(daf[['Pi']])), \n",
    "\t\tDivergence   = c(divergence[['D0']],divergence[['Di']]),\n",
    "\t\trow.names    = c('Neutral class','Selected class')\n",
    "\t)\n",
    "\t\n",
    "\t##Polymorphism and Divergence variables\n",
    "\tP0 = sum(daf[['P0']])\n",
    "\tPi = sum(daf[['Pi']])\n",
    "\tD0 = divergence[['D0']]\n",
    "\tDi = divergence[['Di']]\n",
    "\tm0 = divergence[['m0']]\n",
    "\tmi = divergence[['mi']]\n",
    "\n",
    "\n",
    "\t## Run asymptotic MKT and retrieve alphas \n",
    "\t## iMKT only fits exponential model in asymptotic alpha. it uses asymptoticMKExp()\n",
    "\n",
    "\tasymptoticMkTable = asymptoticMKExp(daf, divergence, xlow, xhigh)\n",
    "\talphaAsymptotic   = as.numeric(asymptoticMkTable[['alphaAsymptotic']])\n",
    "\talphaStandard     = as.numeric(asymptoticMkTable[['alphaOriginal']])\n",
    "\talphaCiLow        = asymptoticMkTable[['ciLow']] \n",
    "\talphaCiHigh       = asymptoticMkTable[['ciHigh']] \n",
    "\t\t\n",
    "\t## Estimate alpha for each DAF category\n",
    "\tdaf[['alpha']] = 1-((as.numeric(D0)*as.numeric(daf[['Pi']]))/(as.numeric(Di)*as.numeric(daf[['P0']])))\n",
    "\n",
    "    ## Estimate the synonymous and non-synonymous ratio\n",
    "\tsynonymousRatio    = P0/m0\n",
    "\tnonSynonymousRatio = Pi/mi \n",
    "\t\n",
    "\t## Estimate the fraction of neutral sites incluiding weakly deleterious variants\n",
    "\tfb  = nonSynonymousRatio/synonymousRatio\n",
    "\t\n",
    "\t## Estimate the fraction of strongly deleleterious sites (d)\n",
    "\td  = 1 - fb\n",
    "\t\n",
    "\t## Estimate the fraction of sligthly deleterious sites in each daf category (b)\n",
    "\twd = daf[['Pi']] - (((1 - alphaAsymptotic) * divergence[['Di']] *  daf[['P0']])/divergence[['D0']])\n",
    "\tprint(wd)\n",
    "    b  = (sum(wd)/sum(daf[['P0']]))*(m0/mi)\n",
    "\n",
    "\t## Re-estimate the truly number of neutral sites, removing the slightly deleterious \n",
    "\tf = fb - b\n",
    "\n",
    "# \tfraction = data.frame(d = d, f = f, b = b)\n",
    "\n",
    "\t## Return output\n",
    "\treturn(asymptoticMkTable) \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Asymptotic execution\n",
    "asymptoticMKExp = function(daf, divergence, xlow, xhigh, seed=NULL) {\n",
    "\t\n",
    "\t## Check data\n",
    "\t# check = checkInput(daf, divergence, xlow, xhigh)\n",
    "\t\n",
    "\t# if(check$data == FALSE) {\n",
    "\t# \tstop(check$print_errors) }\n",
    "\t\n",
    "\tif (any(daf$P0 == 0)){ ## Warning P0\n",
    "\t\twarning('Input daf file contains P0 values = 0.\\nThis can bias the function fitting and the estimation of alpha.')}\n",
    "\t\n",
    "# \t## Check seed\n",
    "# \tif(missing(seed)) {\n",
    "# \t\tseed = NULL\n",
    "# \t} else {\n",
    "# \t\tset.seed(seed)\n",
    "# \t}\n",
    "\t\n",
    "\t## Parse the data from argument x\n",
    "\tf  = daf$daf #derived alelle frequencies\n",
    "\tp  = daf$Pi #non-synonymous polymorphism \n",
    "\tp0 = daf$P0 #synonymous polymorphism\n",
    "# \tprint(daf)\n",
    "\t## Parse the data from argument y\n",
    "\tm  = divergence$mi #number of non-synonymous analyzed positions   \n",
    "\tm0 = divergence$m0 ##number of synonymous analyzed positions\n",
    "\td  = divergence$Di #non-synonymous divergence\n",
    "\td0 = divergence$D0 #synonymous divergence\n",
    "\t\n",
    "\t## Compute alpha values and trim\n",
    "#     print(d0/d)\n",
    "#     print(p/p0)\n",
    "#     print(as.numeric(d0/d) * (p/p0))\n",
    "\talpha         = 1 - (d0/d) * (p/p0)\n",
    "\tcutoff_f1     = xlow\n",
    "\tcutoff_f2     = xhigh\n",
    "\ttrim          = ((f >= cutoff_f1) & (f <= cutoff_f2))\n",
    "\tf_trimmed     = f[trim]\n",
    "\talpha_trimmed = alpha[trim]\n",
    "# \tprint('alpha')\n",
    "#     print(alpha)\n",
    "#     print('cutoff_f1')\n",
    "#     print(cutoff_f1)\n",
    "#     print('cutoff_f2')\n",
    "#     print(cutoff_f2)\n",
    "#     print('trim')\n",
    "#     print(trim)\n",
    "#     print('f_trimmed')\n",
    "#     print(f_trimmed)\n",
    "#     print('alpha_trimmed')\n",
    "#     print(alpha_trimmed)\n",
    "\t## Compute the original MK alpha\n",
    "\talpha_nonasymp = 1 - (d0/d) * (sum(p[trim])/sum(p0[trim])) #using trimmed values\n",
    "\t## Two-step nls2() model fit at a given level of precision (res)\n",
    "    mod1 = fitMKmodel(alpha_trimmed, f_trimmed, 10)\n",
    "\n",
    "    ## If mod1 did not work, try a deeper scan for a decent fit (res=20)\n",
    "\tif (length(mod1) == 0) {\n",
    "\t\tmod1 = fitMKmodel(alpha_trimmed, f_trimmed, 20)\n",
    "\t} \n",
    "\ttryCatch({\n",
    "\t\tmod2 = lm(alpha_trimmed ~ f_trimmed)\n",
    "\t}, error=function(cond) {})\n",
    "\t\n",
    "\ttryCatch({\n",
    "\t\tci_pred = predictNLS(mod1, newdata=data.frame(f_trimmed=1.0))\n",
    "\t\talpha_1_low = ci_pred[6]\n",
    "\t\talpha_1_high = ci_pred[7]\n",
    "\n",
    "\t\t## Preparation of ouput (alpha asym, a, b, c)\n",
    "\t\talpha_1_est = predict(mod1, newdata=data.frame(f_trimmed=1.0))\n",
    "\t\tconst_a = coef(mod1)['const_a']\n",
    "\t\tconst_b = coef(mod1)['const_b']\n",
    "\t\tconst_c = coef(mod1)['const_c']\n",
    "\t\t\n",
    "\t\t## Output table\n",
    "\t\tresult_df = data.frame(model='exponential', a=const_a, b=const_b, c=const_c, alphaAsymptotic=alpha_1_est, ciLow=alpha_1_low, ciHigh=alpha_1_high, alphaOriginal=alpha_nonasymp, row.names=NULL)\n",
    "\t\treturn(result_df)\n",
    "\t}, error=function(cond) {cat('Could not fit exponential model for the computation of asymptotic alpha.\\n')})\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Compute confidence intervals of alpha using predictNLS \n",
    "## Get a CI using Monte Carlo simulation based upon a fitted model.  \n",
    "## Thanks to Andrej-Nikolai Spiess (http://www.dr-spiess.de) for this code.\n",
    "predictNLS = function(object, newdata, level = 0.95, nsim = 10000) {\n",
    "\t  \n",
    "\t## get right-hand side of formula\n",
    "\tRHS  = as.list(object$call$formula)[[3]]\n",
    "#     print('RHS')\n",
    "#     print(RHS)\n",
    "\tEXPR = as.expression(RHS)\n",
    "#     print('EXPR')\n",
    "#     print(EXPR)\n",
    "\t\n",
    "\t## all variables in model\n",
    "\tVARS = all.vars(EXPR)\n",
    "#     print('VARS')\n",
    "#     print(VARS)\n",
    "\t\n",
    "\t## coefficients\n",
    "\tCOEF = coef(object)\n",
    "#     print('COEF')\n",
    "#     print(COEF)\n",
    "\t\n",
    "\t## extract predictor variable    \n",
    "\tpredNAME = setdiff(VARS, names(COEF))  \n",
    "#     print(predNAME)\n",
    "\t\n",
    "\t## take fitted values, if 'newdata' is missing\n",
    "\tif (missing(newdata)) {\n",
    "\t\tnewdata           = eval(object$data)[predNAME]\n",
    "\t\tcolnames(newdata) = predNAME\n",
    "\t}\n",
    "\t  \n",
    "\t## check that 'newdata' has same name as predVAR\n",
    "\tif (names(newdata)[1] != predNAME) stop(\"newdata should have name '\", predNAME, \"'!\")\n",
    "\n",
    "\t## get variance-covariance matrix\n",
    "\tVCOV = vcov(object)\n",
    "#     print('VCOV')\n",
    "#     print(VCOV)\n",
    "\n",
    "\t## augment variance-covariance matrix for 'mvrnorm' \n",
    "\t## by adding a column/row for 'error in x'\n",
    "\tNCOL = ncol(VCOV)\n",
    "\tADD1 = c(rep(0, NCOL))\n",
    "\tADD1 = matrix(ADD1, ncol = 1)\n",
    "\tcolnames(ADD1) = predNAME\n",
    "\tVCOV = cbind(VCOV, ADD1)\n",
    "\tADD2 = c(rep(0, NCOL + 1))\n",
    "\tADD2 = matrix(ADD2, nrow = 1)\n",
    "\trownames(ADD2) = predNAME\n",
    "\tVCOV = rbind(VCOV, ADD2) \n",
    "\n",
    "\t## iterate over all entries in 'newdata' as in usual 'predict.' functions\n",
    "\tNR = nrow(newdata)\n",
    "\trespVEC = numeric(NR)\n",
    "\tseVEC = numeric(NR)\n",
    "\tvarPLACE = ncol(VCOV)   \n",
    "\n",
    "\t## define counter function\n",
    "\tcounter = function(i) {\n",
    "\t\tif (i%%10 == 0) { cat(i) \n",
    "\t} else { cat(\".\") }\n",
    "\t\tif (i%%50 == 0) { cat(\"\\n\") }\n",
    "\t\tflush.console()\n",
    "\t}\n",
    "\t  \n",
    "\t## create output matrix (df)\n",
    "\toutMAT = NULL \n",
    "\t\n",
    "\tfor (i in 1:NR) {\n",
    "\t\t\n",
    "\t\t## get predictor values and optional errors\n",
    "\t\tpredVAL = newdata[i, 1]\n",
    "\t\tif (ncol(newdata) == 2) predERROR = newdata[i, 2] else predERROR = 0\n",
    "\t\tnames(predVAL) = predNAME  \n",
    "\t\tnames(predERROR) = predNAME  \n",
    "\t\t\n",
    "\t\t## create mean vector for 'mvrnorm'\n",
    "\t\tMU = c(COEF, predVAL)\n",
    "\t\t\n",
    "\t\t## create variance-covariance matrix for 'mvrnorm'\n",
    "\t\t## by putting error^2 in lower-right position of VCOV\n",
    "\t\tnewVCOV = VCOV\n",
    "\t\tnewVCOV[varPLACE, varPLACE] = predERROR^2\n",
    "\t\t## create MC simulation matrix\n",
    "\t\tsimMAT = mvrnorm(n = nsim, mu = MU, Sigma = newVCOV, empirical = TRUE)\n",
    "# \t\tprint(summary(simMAT))\n",
    "\t\t## evaluate expression on rows of simMAT\n",
    "\t\tEVAL = try(eval(EXPR, envir = as.data.frame(simMAT)), silent = TRUE)\n",
    "\t\tif (inherits(EVAL, \"try-error\")) stop(\"There was an error evaluating the simulations!\")\n",
    "\t\t\n",
    "\t\t## collect statistics\n",
    "\t\tPRED = data.frame(predVAL)\n",
    "\t\tcolnames(PRED) = predNAME\n",
    "\t\tFITTED = predict(object, newdata = data.frame(PRED))\n",
    "\t\tMEAN.sim = mean(EVAL, na.rm = TRUE)\n",
    "\t\tSD.sim = sd(EVAL, na.rm = TRUE)\n",
    "\t\tMEDIAN.sim = median(EVAL, na.rm = TRUE)\n",
    "\t\tMAD.sim = mad(EVAL, na.rm = TRUE)\n",
    "\t\tQUANT = quantile(EVAL, c((1 - level)/2, level + (1 - level)/2))\n",
    "\t\tRES = c(FITTED, MEAN.sim, SD.sim, MEDIAN.sim, MAD.sim, QUANT[1], QUANT[2])\n",
    "\t\toutMAT = rbind(outMAT, RES)\n",
    "\t}\n",
    "\t  \n",
    "\tcolnames(outMAT) = c(\"fit\", \"mean\", \"sd\", \"median\", \"mad\", names(QUANT[1]), names(QUANT[2]))\n",
    "\trownames(outMAT) = NULL\n",
    "#     print(outMAT)\n",
    "    return(outMAT)      \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Two-step nls2() model fit at a given level of precision (res)\n",
    "fitMKmodel = function(alpha_trimmed, f_trimmed, res) {\n",
    "\t\n",
    "\t## First fitting using starting values (st)\n",
    "# \tmod = tryCatch({\n",
    "\t\t\n",
    "# \t\t## Starting values to fit the model  \n",
    "# \t\tst = expand.grid(const_a=seq(-1,1,length.out=res + 1), const_b=seq(-1,1,length.out=res), const_c=seq(1,10,length.out=res + 1))\n",
    "\t\t\n",
    "# \t\t## Fitting\n",
    "# \t\tnls2::nls2(alpha_trimmed ~ const_a + const_b * exp(-const_c* f_trimmed), start=st, algorithm='brute-force', control=nls.control(maxiter=NROW(st)))\n",
    "\t\t\n",
    "# \t}, error=function(cond) {}) ## Return condition of error when unable to fit\n",
    "\t\n",
    "    st = expand.grid(const_a=seq(-1,1,length.out=res + 1), const_b=seq(-1,1,length.out=res), const_c=seq(1,10,length.out=res + 1))\n",
    "    mod <- nls2::nls2(alpha_trimmed ~ const_a + const_b * exp(-const_c* f_trimmed),\n",
    "                      start=st, algorithm='brute-force', control=nls.control(maxiter=NROW(st)))\n",
    "    \n",
    "\t## If mod fails...\n",
    "\tif (length(mod) == 0) { return(NULL) }\n",
    "\t\n",
    "\t## Second fitting, starting from previous fit (mod)\n",
    "\tmod2 = tryCatch({\n",
    "\t\tnls2::nls2(alpha_trimmed ~ const_a + const_b * exp(-const_c* f_trimmed), start = mod, control=nls.control(maxiter=200))\n",
    "\t\t\n",
    "\t}, error=function(cond) {}) ## Same error handling than the previous step\n",
    "\t\n",
    "\t## If mod2 fails...\n",
    "\tif (length(mod2) == 0) { return(NULL) }\n",
    "\t\n",
    "\t## Return mod2 if fitted\n",
    "\treturn(mod2)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 14861\n"
     ]
    }
   ],
   "source": [
    "approach <- 'aa'\n",
    "test_mode <- 'aMKT'\n",
    "pop <- 'EUR'\n",
    "cutoff <- c(0.15)\n",
    "\n",
    "data <- read.delim(paste(data_dir, \"metaPops.tsv\", sep=''))\n",
    "\n",
    "gene_df <- read.csv(paste(data_dir, 'aa_genes.csv', sep=''), header=FALSE)\n",
    "\n",
    "idx <- 1\n",
    "\n",
    "\n",
    "gene_list <- as.character(gene_df[gene_df[,(gene_df[1,]=='W1') & (gene_df[2,]=='OFC')] == 1,1])\n",
    "print(length(gene_list))\n",
    "df <- data[data[,'ID'] %in% gene_list,]\n",
    "df <- df[df[,'Population'] == pop,]\n",
    "x <- makeSfs(df, cumu=TRUE)\n",
    "daf <- x[['daf']]\n",
    "div <- x[['div']]\n",
    "# PopHumanAnalysisMod(genes=gene_list, pops=pop, test=test_mode, plot=FALSE, cutoff = cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.366   0.000   0.395 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time({eMKT(daf,div)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 53807.3036702  1072.9899274   489.4936429   146.2357019   -23.0912757\n",
      " [6]   -26.2452442   -86.4392706  -134.1159682  -179.4219284  -114.0639685\n",
      "[11]  -144.1153842  -115.5236186    12.8039430    20.0596286    54.1894617\n",
      "[16]    66.0994079    64.5667407    32.1820845     0.5553829    11.9272615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   user  system elapsed \n",
       "  0.626   0.220   0.582 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "system.time({aMKT(daf,div)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 53807.3036702  1072.9899274   489.4936429   146.2357019   -23.0912757\n",
      " [6]   -26.2452442   -86.4392706  -134.1159682  -179.4219284  -114.0639685\n",
      "[11]  -144.1153842  -115.5236186    12.8039430    20.0596286    54.1894617\n",
      "[16]    66.0994079    64.5667407    32.1820845     0.5553829    11.9272615\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<caption>A data.frame: 1 × 8</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>model</th><th scope=col>a</th><th scope=col>b</th><th scope=col>c</th><th scope=col>alphaAsymptotic</th><th scope=col>ciLow</th><th scope=col>ciHigh</th><th scope=col>alphaOriginal</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>exponential</td><td>0.08762747</td><td>-2.478785</td><td>46.12182</td><td>0.08762747</td><td>0.07858098</td><td>0.09683765</td><td>-0.214113</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A data.frame: 1 × 8\n",
       "\\begin{tabular}{llllllll}\n",
       " model & a & b & c & alphaAsymptotic & ciLow & ciHigh & alphaOriginal\\\\\n",
       " <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t exponential & 0.08762747 & -2.478785 & 46.12182 & 0.08762747 & 0.07858098 & 0.09683765 & -0.214113\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A data.frame: 1 × 8\n",
       "\n",
       "| model &lt;fct&gt; | a &lt;dbl&gt; | b &lt;dbl&gt; | c &lt;dbl&gt; | alphaAsymptotic &lt;dbl&gt; | ciLow &lt;dbl&gt; | ciHigh &lt;dbl&gt; | alphaOriginal &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|\n",
       "| exponential | 0.08762747 | -2.478785 | 46.12182 | 0.08762747 | 0.07858098 | 0.09683765 | -0.214113 |\n",
       "\n"
      ],
      "text/plain": [
       "  model       a          b         c        alphaAsymptotic ciLow     \n",
       "1 exponential 0.08762747 -2.478785 46.12182 0.08762747      0.07858098\n",
       "  ciHigh     alphaOriginal\n",
       "1 0.09683765 -0.214113    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "aMKT(daf,div)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [1] 0.05 0.05 0.15 0.15 0.25 0.25 0.35 0.35 0.45 0.45 0.55 0.55 0.65 0.65 0.75\n",
      "[16] 0.75 0.85 0.85 0.95 0.95\n"
     ]
    }
   ],
   "source": [
    "if (nrow(daf) == 20) {\n",
    "  \t\tdaf1 <- daf\n",
    "  \t\tdaf1$daf10 <- sort(rep(seq(0.05,0.95,0.1),2)) ## Add column with the daf10 frequencies\n",
    "        print(daf1$daf10)\n",
    "  \t\tdaf1 <- daf1[c(\"daf10\",\"Pi\",\"P0\")] ## Keep new frequencies, Pi and P0\n",
    "  \t\tdaf1 <- aggregate(. ~ daf10, data=daf1, FUN=sum)\t## Sum Pi and P0 two by two based on daf\n",
    "  \t\tcolnames(daf1)<-c(\"daf\",\"Pi\",\"P0\") ## Final daf columns name\n",
    "  \t\t\n",
    "  \t\t}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
